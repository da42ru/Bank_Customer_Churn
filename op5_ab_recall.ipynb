{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8305d2b-05a2-4c03-96c1-41a8ed3e3f4e",
   "metadata": {},
   "source": [
    "## AdaBoost Hyperparameter Tuning (Recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1737f07b-25d7-4e9a-950e-c41ea036b4c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load Libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "34b40b44-1c92-4b9d-ad57-3cddb44f6f0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load Data\n",
    "\n",
    "df = pd.read_csv('bank_4.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e25031a8-fef1-4150-86e7-8b7e22f0a9bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train / Test Split\n",
    "\n",
    "X = df.drop(columns=['churn', 'complain', 'umap_1', 'umap_2'])\n",
    "y = df['churn']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2b530e97-2bc3-4b3d-b9f8-eb4ed610ff66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Hyperparameter tuning\n",
    "\n",
    "def objective(trial):\n",
    "\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 1000),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.001, 1.0)\n",
    "    }\n",
    "\n",
    "    model = AdaBoostClassifier(\n",
    "        **params,\n",
    "        random_state=42)\n",
    "    \n",
    "    threshold = 0.5\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n",
    "    scores = []\n",
    "    \n",
    "    for tr, te in skf.split(X_train, y_train):\n",
    "        \n",
    "        X_tr, X_te = X_train.iloc[tr], X_train.iloc[te]\n",
    "        y_tr, y_te = y_train.iloc[tr], y_train.iloc[te]\n",
    "        \n",
    "        model.fit(X_tr, y_tr)\n",
    "        prob = model.predict_proba(X_te)[:, 1]\n",
    "        y_pred = np.where(prob < threshold, 0, 1)\n",
    "        \n",
    "        scores.append(recall_score(y_te, y_pred))\n",
    "        \n",
    "    return np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "eb85a387-214c-480a-8a96-d69570dcbce9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-08 21:49:48,910] A new study created in memory with name: no-name-dcdf618b-333b-4ca1-b77b-e9d1b66ac665\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c03555c80c4643ab831a63664c7bea1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2024-07-08 21:50:09,386] Trial 0 finished with value: 0.4484662576687117 and parameters: {'n_estimators': 953, 'learning_rate': 0.8618864425510021}. Best is trial 0 with value: 0.4484662576687117.\n",
      "[I 2024-07-08 21:50:18,664] Trial 1 finished with value: 0.44907975460122695 and parameters: {'n_estimators': 443, 'learning_rate': 0.6682053805700706}. Best is trial 1 with value: 0.44907975460122695.\n",
      "[I 2024-07-08 21:50:32,704] Trial 2 finished with value: 0.4441717791411043 and parameters: {'n_estimators': 686, 'learning_rate': 0.11106321149959954}. Best is trial 1 with value: 0.44907975460122695.\n",
      "[I 2024-07-08 21:50:40,388] Trial 3 finished with value: 0.4404907975460123 and parameters: {'n_estimators': 371, 'learning_rate': 0.1652324979178452}. Best is trial 1 with value: 0.44907975460122695.\n",
      "[I 2024-07-08 21:50:49,201] Trial 4 finished with value: 0.4466257668711656 and parameters: {'n_estimators': 406, 'learning_rate': 0.3250376281030502}. Best is trial 1 with value: 0.44907975460122695.\n",
      "[I 2024-07-08 21:51:07,669] Trial 5 finished with value: 0.44601226993865034 and parameters: {'n_estimators': 831, 'learning_rate': 0.12853681148780052}. Best is trial 1 with value: 0.44907975460122695.\n",
      "[I 2024-07-08 21:51:24,701] Trial 6 finished with value: 0.4484662576687117 and parameters: {'n_estimators': 852, 'learning_rate': 0.7805460011947776}. Best is trial 1 with value: 0.44907975460122695.\n",
      "[I 2024-07-08 21:51:38,280] Trial 7 finished with value: 0.4484662576687117 and parameters: {'n_estimators': 673, 'learning_rate': 0.9008681432817445}. Best is trial 1 with value: 0.44907975460122695.\n",
      "[I 2024-07-08 21:51:50,737] Trial 8 finished with value: 0.4466257668711656 and parameters: {'n_estimators': 621, 'learning_rate': 0.18157273597340431}. Best is trial 1 with value: 0.44907975460122695.\n",
      "[I 2024-07-08 21:51:57,068] Trial 9 finished with value: 0.44355828220858895 and parameters: {'n_estimators': 313, 'learning_rate': 0.21865297398156502}. Best is trial 1 with value: 0.44907975460122695.\n",
      "[I 2024-07-08 21:51:58,179] Trial 10 finished with value: 0.4374233128834356 and parameters: {'n_estimators': 53, 'learning_rate': 0.6234913424007885}. Best is trial 1 with value: 0.44907975460122695.\n",
      "[I 2024-07-08 21:52:17,776] Trial 11 finished with value: 0.4484662576687117 and parameters: {'n_estimators': 983, 'learning_rate': 0.9995285289495417}. Best is trial 1 with value: 0.44907975460122695.\n",
      "[I 2024-07-08 21:52:22,491] Trial 12 finished with value: 0.447239263803681 and parameters: {'n_estimators': 231, 'learning_rate': 0.6186200089853322}. Best is trial 1 with value: 0.44907975460122695.\n",
      "[I 2024-07-08 21:52:32,870] Trial 13 finished with value: 0.4484662576687117 and parameters: {'n_estimators': 505, 'learning_rate': 0.7549843644700143}. Best is trial 1 with value: 0.44907975460122695.\n",
      "[I 2024-07-08 21:52:43,593] Trial 14 finished with value: 0.447239263803681 and parameters: {'n_estimators': 528, 'learning_rate': 0.5411987517677421}. Best is trial 1 with value: 0.44907975460122695.\n",
      "[I 2024-07-08 21:53:03,273] Trial 15 finished with value: 0.4478527607361963 and parameters: {'n_estimators': 976, 'learning_rate': 0.4108003829541332}. Best is trial 1 with value: 0.44907975460122695.\n",
      "[I 2024-07-08 21:53:06,686] Trial 16 finished with value: 0.4478527607361963 and parameters: {'n_estimators': 171, 'learning_rate': 0.7630182662882067}. Best is trial 1 with value: 0.44907975460122695.\n",
      "[I 2024-07-08 21:53:16,717] Trial 17 finished with value: 0.4484662576687117 and parameters: {'n_estimators': 493, 'learning_rate': 0.8559601898768888}. Best is trial 1 with value: 0.44907975460122695.\n",
      "[I 2024-07-08 21:53:32,111] Trial 18 finished with value: 0.4484662576687117 and parameters: {'n_estimators': 754, 'learning_rate': 0.639588637115578}. Best is trial 1 with value: 0.44907975460122695.\n",
      "[I 2024-07-08 21:53:44,386] Trial 19 finished with value: 0.4484662576687117 and parameters: {'n_estimators': 602, 'learning_rate': 0.9753472512628235}. Best is trial 1 with value: 0.44907975460122695.\n",
      "[I 2024-07-08 21:54:04,199] Trial 20 finished with value: 0.4478527607361963 and parameters: {'n_estimators': 846, 'learning_rate': 0.44442911285202447}. Best is trial 1 with value: 0.44907975460122695.\n",
      "[I 2024-07-08 21:54:23,020] Trial 21 finished with value: 0.4484662576687117 and parameters: {'n_estimators': 896, 'learning_rate': 0.7472991044459768}. Best is trial 1 with value: 0.44907975460122695.\n",
      "[I 2024-07-08 21:54:38,545] Trial 22 finished with value: 0.4484662576687117 and parameters: {'n_estimators': 769, 'learning_rate': 0.8360524095135311}. Best is trial 1 with value: 0.44907975460122695.\n",
      "[I 2024-07-08 21:54:58,091] Trial 23 finished with value: 0.4484662576687117 and parameters: {'n_estimators': 930, 'learning_rate': 0.6998054458987707}. Best is trial 1 with value: 0.44907975460122695.\n",
      "[I 2024-07-08 21:55:14,573] Trial 24 finished with value: 0.4484662576687117 and parameters: {'n_estimators': 788, 'learning_rate': 0.5260313308730118}. Best is trial 1 with value: 0.44907975460122695.\n",
      "[I 2024-07-08 21:55:32,775] Trial 25 finished with value: 0.4484662576687117 and parameters: {'n_estimators': 898, 'learning_rate': 0.8656097465154998}. Best is trial 1 with value: 0.44907975460122695.\n",
      "[I 2024-07-08 21:55:41,371] Trial 26 finished with value: 0.4484662576687117 and parameters: {'n_estimators': 430, 'learning_rate': 0.6907951616922594}. Best is trial 1 with value: 0.44907975460122695.\n",
      "[I 2024-07-08 21:55:55,616] Trial 27 finished with value: 0.4484662576687117 and parameters: {'n_estimators': 705, 'learning_rate': 0.9207271361016589}. Best is trial 1 with value: 0.44907975460122695.\n",
      "[I 2024-07-08 21:56:07,707] Trial 28 finished with value: 0.4484662576687117 and parameters: {'n_estimators': 594, 'learning_rate': 0.8041970025500365}. Best is trial 1 with value: 0.44907975460122695.\n",
      "[I 2024-07-08 21:56:14,713] Trial 29 finished with value: 0.4484662576687117 and parameters: {'n_estimators': 311, 'learning_rate': 0.571728932598155}. Best is trial 1 with value: 0.44907975460122695.\n",
      "[I 2024-07-08 21:56:28,720] Trial 30 finished with value: 0.42085889570552143 and parameters: {'n_estimators': 687, 'learning_rate': 0.03155094642812767}. Best is trial 1 with value: 0.44907975460122695.\n",
      "[I 2024-07-08 21:56:46,517] Trial 31 finished with value: 0.4484662576687117 and parameters: {'n_estimators': 839, 'learning_rate': 0.8911219997305703}. Best is trial 1 with value: 0.44907975460122695.\n",
      "[I 2024-07-08 21:57:01,897] Trial 32 finished with value: 0.4484662576687117 and parameters: {'n_estimators': 722, 'learning_rate': 0.9538625731448431}. Best is trial 1 with value: 0.44907975460122695.\n",
      "[I 2024-07-08 21:57:15,672] Trial 33 finished with value: 0.4484662576687117 and parameters: {'n_estimators': 656, 'learning_rate': 0.80739361309267}. Best is trial 1 with value: 0.44907975460122695.\n",
      "[I 2024-07-08 21:57:27,816] Trial 34 finished with value: 0.4484662576687117 and parameters: {'n_estimators': 552, 'learning_rate': 0.9120845931653873}. Best is trial 1 with value: 0.44907975460122695.\n",
      "[I 2024-07-08 21:57:48,912] Trial 35 finished with value: 0.4484662576687117 and parameters: {'n_estimators': 1000, 'learning_rate': 0.7232197298551436}. Best is trial 1 with value: 0.44907975460122695.\n",
      "[I 2024-07-08 21:57:57,681] Trial 36 finished with value: 0.4478527607361963 and parameters: {'n_estimators': 423, 'learning_rate': 0.66546854907809}. Best is trial 1 with value: 0.44907975460122695.\n",
      "[I 2024-07-08 21:58:17,646] Trial 37 finished with value: 0.4484662576687117 and parameters: {'n_estimators': 925, 'learning_rate': 0.7954079593533847}. Best is trial 1 with value: 0.44907975460122695.\n",
      "[I 2024-07-08 21:58:35,527] Trial 38 finished with value: 0.4484662576687117 and parameters: {'n_estimators': 832, 'learning_rate': 0.5882635177320075}. Best is trial 1 with value: 0.44907975460122695.\n",
      "[I 2024-07-08 21:58:43,155] Trial 39 finished with value: 0.4447852760736197 and parameters: {'n_estimators': 347, 'learning_rate': 0.2525751700926959}. Best is trial 1 with value: 0.44907975460122695.\n",
      "[I 2024-07-08 21:58:52,823] Trial 40 finished with value: 0.4478527607361963 and parameters: {'n_estimators': 468, 'learning_rate': 0.46701352946461694}. Best is trial 1 with value: 0.44907975460122695.\n",
      "[I 2024-07-08 21:59:11,790] Trial 41 finished with value: 0.4484662576687117 and parameters: {'n_estimators': 935, 'learning_rate': 0.9950814280207226}. Best is trial 1 with value: 0.44907975460122695.\n",
      "[I 2024-07-08 21:59:30,752] Trial 42 finished with value: 0.4484662576687117 and parameters: {'n_estimators': 876, 'learning_rate': 0.9392419558615837}. Best is trial 1 with value: 0.44907975460122695.\n",
      "[I 2024-07-08 21:59:52,752] Trial 43 finished with value: 0.4484662576687117 and parameters: {'n_estimators': 970, 'learning_rate': 0.8986757520326042}. Best is trial 1 with value: 0.44907975460122695.\n",
      "[I 2024-07-08 22:00:10,852] Trial 44 finished with value: 0.4484662576687117 and parameters: {'n_estimators': 806, 'learning_rate': 0.9935266185278591}. Best is trial 1 with value: 0.44907975460122695.\n",
      "[I 2024-07-08 22:00:34,626] Trial 45 finished with value: 0.4484662576687117 and parameters: {'n_estimators': 975, 'learning_rate': 0.845065600148976}. Best is trial 1 with value: 0.44907975460122695.\n",
      "[I 2024-07-08 22:00:49,563] Trial 46 finished with value: 0.4484662576687117 and parameters: {'n_estimators': 654, 'learning_rate': 0.7720038343197905}. Best is trial 1 with value: 0.44907975460122695.\n",
      "[I 2024-07-08 22:01:10,331] Trial 47 finished with value: 0.4484662576687117 and parameters: {'n_estimators': 876, 'learning_rate': 0.8655480427694286}. Best is trial 1 with value: 0.44907975460122695.\n",
      "[I 2024-07-08 22:01:16,330] Trial 48 finished with value: 0.44907975460122695 and parameters: {'n_estimators': 257, 'learning_rate': 0.9412573858058888}. Best is trial 1 with value: 0.44907975460122695.\n",
      "[I 2024-07-08 22:01:21,081] Trial 49 finished with value: 0.44907975460122695 and parameters: {'n_estimators': 207, 'learning_rate': 0.73078250787047}. Best is trial 1 with value: 0.44907975460122695.\n",
      "[I 2024-07-08 22:01:23,734] Trial 50 finished with value: 0.43865030674846633 and parameters: {'n_estimators': 129, 'learning_rate': 0.3501773601522471}. Best is trial 1 with value: 0.44907975460122695.\n",
      "[I 2024-07-08 22:01:28,914] Trial 51 finished with value: 0.4484662576687117 and parameters: {'n_estimators': 234, 'learning_rate': 0.7242252234613274}. Best is trial 1 with value: 0.44907975460122695.\n",
      "[I 2024-07-08 22:01:35,330] Trial 52 finished with value: 0.447239263803681 and parameters: {'n_estimators': 247, 'learning_rate': 0.8204388215296434}. Best is trial 1 with value: 0.44907975460122695.\n",
      "[I 2024-07-08 22:01:36,678] Trial 53 finished with value: 0.4374233128834356 and parameters: {'n_estimators': 52, 'learning_rate': 0.6501063973740042}. Best is trial 1 with value: 0.44907975460122695.\n",
      "[I 2024-07-08 22:01:40,348] Trial 54 finished with value: 0.4466257668711656 and parameters: {'n_estimators': 135, 'learning_rate': 0.7653324241590916}. Best is trial 1 with value: 0.44907975460122695.\n",
      "[I 2024-07-08 22:01:46,805] Trial 55 finished with value: 0.4484662576687117 and parameters: {'n_estimators': 282, 'learning_rate': 0.8747077388032715}. Best is trial 1 with value: 0.44907975460122695.\n",
      "[I 2024-07-08 22:01:51,867] Trial 56 finished with value: 0.4478527607361963 and parameters: {'n_estimators': 213, 'learning_rate': 0.9631720785888349}. Best is trial 1 with value: 0.44907975460122695.\n",
      "[I 2024-07-08 22:02:01,493] Trial 57 finished with value: 0.447239263803681 and parameters: {'n_estimators': 390, 'learning_rate': 0.7144630356032398}. Best is trial 1 with value: 0.44907975460122695.\n",
      "[I 2024-07-08 22:02:03,696] Trial 58 finished with value: 0.4429447852760736 and parameters: {'n_estimators': 91, 'learning_rate': 0.6048522222069013}. Best is trial 1 with value: 0.44907975460122695.\n",
      "[I 2024-07-08 22:02:07,533] Trial 59 finished with value: 0.4484662576687117 and parameters: {'n_estimators': 178, 'learning_rate': 0.9340993752407087}. Best is trial 1 with value: 0.44907975460122695.\n",
      "[I 2024-07-08 22:02:25,093] Trial 60 finished with value: 0.4484662576687117 and parameters: {'n_estimators': 737, 'learning_rate': 0.7897594931978364}. Best is trial 1 with value: 0.44907975460122695.\n",
      "[I 2024-07-08 22:02:36,649] Trial 61 finished with value: 0.4484662576687117 and parameters: {'n_estimators': 567, 'learning_rate': 0.8447518033757035}. Best is trial 1 with value: 0.44907975460122695.\n",
      "[I 2024-07-08 22:02:44,500] Trial 62 finished with value: 0.4484662576687117 and parameters: {'n_estimators': 348, 'learning_rate': 0.9080006892707819}. Best is trial 1 with value: 0.44907975460122695.\n",
      "[I 2024-07-08 22:03:05,062] Trial 63 finished with value: 0.4484662576687117 and parameters: {'n_estimators': 928, 'learning_rate': 0.9501097099540982}. Best is trial 1 with value: 0.44907975460122695.\n",
      "[I 2024-07-08 22:03:14,956] Trial 64 finished with value: 0.447239263803681 and parameters: {'n_estimators': 464, 'learning_rate': 0.6726526182500567}. Best is trial 1 with value: 0.44907975460122695.\n",
      "[I 2024-07-08 22:03:34,685] Trial 65 finished with value: 0.4484662576687117 and parameters: {'n_estimators': 948, 'learning_rate': 0.7508504680902519}. Best is trial 1 with value: 0.44907975460122695.\n",
      "[I 2024-07-08 22:03:40,346] Trial 66 finished with value: 0.447239263803681 and parameters: {'n_estimators': 277, 'learning_rate': 0.8276981175209909}. Best is trial 1 with value: 0.44907975460122695.\n",
      "[I 2024-07-08 22:04:02,229] Trial 67 finished with value: 0.4484662576687117 and parameters: {'n_estimators': 997, 'learning_rate': 0.8842756432614426}. Best is trial 1 with value: 0.44907975460122695.\n",
      "[I 2024-07-08 22:04:19,659] Trial 68 finished with value: 0.4484662576687117 and parameters: {'n_estimators': 807, 'learning_rate': 0.9799226691419455}. Best is trial 1 with value: 0.44907975460122695.\n",
      "[I 2024-07-08 22:04:40,030] Trial 69 finished with value: 0.4484662576687117 and parameters: {'n_estimators': 894, 'learning_rate': 0.552164891257289}. Best is trial 1 with value: 0.44907975460122695.\n",
      "[I 2024-07-08 22:04:44,640] Trial 70 finished with value: 0.4478527607361963 and parameters: {'n_estimators': 195, 'learning_rate': 0.9327737253939539}. Best is trial 1 with value: 0.44907975460122695.\n",
      "[I 2024-07-08 22:04:55,574] Trial 71 finished with value: 0.4484662576687117 and parameters: {'n_estimators': 521, 'learning_rate': 0.6928913464783636}. Best is trial 1 with value: 0.44907975460122695.\n",
      "[I 2024-07-08 22:05:06,420] Trial 72 finished with value: 0.4484662576687117 and parameters: {'n_estimators': 493, 'learning_rate': 0.7323092072912462}. Best is trial 1 with value: 0.44907975460122695.\n",
      "[I 2024-07-08 22:05:18,269] Trial 73 finished with value: 0.4484662576687117 and parameters: {'n_estimators': 574, 'learning_rate': 0.7940304619537247}. Best is trial 1 with value: 0.44907975460122695.\n",
      "[I 2024-07-08 22:05:31,074] Trial 74 finished with value: 0.4484662576687117 and parameters: {'n_estimators': 628, 'learning_rate': 0.8669735623783398}. Best is trial 1 with value: 0.44907975460122695.\n",
      "[I 2024-07-08 22:05:48,592] Trial 75 finished with value: 0.4484662576687117 and parameters: {'n_estimators': 859, 'learning_rate': 0.6346508399805326}. Best is trial 1 with value: 0.44907975460122695.\n",
      "[I 2024-07-08 22:06:03,993] Trial 76 finished with value: 0.4484662576687117 and parameters: {'n_estimators': 764, 'learning_rate': 0.9030975731025137}. Best is trial 1 with value: 0.44907975460122695.\n",
      "[I 2024-07-08 22:06:14,798] Trial 77 finished with value: 0.4478527607361963 and parameters: {'n_estimators': 530, 'learning_rate': 0.5053870484304088}. Best is trial 1 with value: 0.44907975460122695.\n",
      "[I 2024-07-08 22:06:22,472] Trial 78 finished with value: 0.4484662576687117 and parameters: {'n_estimators': 367, 'learning_rate': 0.7691527532388425}. Best is trial 1 with value: 0.44907975460122695.\n",
      "[I 2024-07-08 22:06:31,120] Trial 79 finished with value: 0.4484662576687117 and parameters: {'n_estimators': 430, 'learning_rate': 0.8213020577321847}. Best is trial 1 with value: 0.44907975460122695.\n",
      "[I 2024-07-08 22:06:49,480] Trial 80 finished with value: 0.4484662576687117 and parameters: {'n_estimators': 904, 'learning_rate': 0.9751323418080908}. Best is trial 1 with value: 0.44907975460122695.\n",
      "[I 2024-07-08 22:07:00,196] Trial 81 finished with value: 0.4484662576687117 and parameters: {'n_estimators': 467, 'learning_rate': 0.8513547532057326}. Best is trial 1 with value: 0.44907975460122695.\n",
      "[I 2024-07-08 22:07:11,203] Trial 82 finished with value: 0.4484662576687117 and parameters: {'n_estimators': 491, 'learning_rate': 0.9142673644095193}. Best is trial 1 with value: 0.44907975460122695.\n",
      "[I 2024-07-08 22:07:33,175] Trial 83 finished with value: 0.4484662576687117 and parameters: {'n_estimators': 951, 'learning_rate': 0.8795226552011062}. Best is trial 1 with value: 0.44907975460122695.\n",
      "[I 2024-07-08 22:07:42,095] Trial 84 finished with value: 0.4484662576687117 and parameters: {'n_estimators': 410, 'learning_rate': 0.8050019670935712}. Best is trial 1 with value: 0.44907975460122695.\n",
      "[I 2024-07-08 22:07:54,977] Trial 85 finished with value: 0.4484662576687117 and parameters: {'n_estimators': 614, 'learning_rate': 0.9556537678549296}. Best is trial 1 with value: 0.44907975460122695.\n",
      "[I 2024-07-08 22:08:01,226] Trial 86 finished with value: 0.4484662576687117 and parameters: {'n_estimators': 306, 'learning_rate': 0.7382316234570344}. Best is trial 1 with value: 0.44907975460122695.\n",
      "[I 2024-07-08 22:08:04,672] Trial 87 finished with value: 0.44907975460122695 and parameters: {'n_estimators': 150, 'learning_rate': 0.7756263285544004}. Best is trial 1 with value: 0.44907975460122695.\n",
      "[I 2024-07-08 22:08:07,961] Trial 88 finished with value: 0.44969325153374234 and parameters: {'n_estimators': 159, 'learning_rate': 0.7814626294518465}. Best is trial 88 with value: 0.44969325153374234.\n",
      "[I 2024-07-08 22:08:10,523] Trial 89 finished with value: 0.4441717791411043 and parameters: {'n_estimators': 125, 'learning_rate': 0.705450793832169}. Best is trial 88 with value: 0.44969325153374234.\n",
      "[I 2024-07-08 22:08:13,972] Trial 90 finished with value: 0.4484662576687117 and parameters: {'n_estimators': 157, 'learning_rate': 0.6754476311428673}. Best is trial 88 with value: 0.44969325153374234.\n",
      "[I 2024-07-08 22:08:15,743] Trial 91 finished with value: 0.4447852760736197 and parameters: {'n_estimators': 84, 'learning_rate': 0.7695308522124641}. Best is trial 88 with value: 0.44969325153374234.\n",
      "[I 2024-07-08 22:08:19,921] Trial 92 finished with value: 0.4478527607361963 and parameters: {'n_estimators': 201, 'learning_rate': 0.7480818873860505}. Best is trial 88 with value: 0.44969325153374234.\n",
      "[I 2024-07-08 22:08:25,176] Trial 93 finished with value: 0.4478527607361963 and parameters: {'n_estimators': 257, 'learning_rate': 0.7897794661395163}. Best is trial 88 with value: 0.44969325153374234.\n",
      "[I 2024-07-08 22:08:28,566] Trial 94 finished with value: 0.4484662576687117 and parameters: {'n_estimators': 158, 'learning_rate': 0.846945591029535}. Best is trial 88 with value: 0.44969325153374234.\n",
      "[I 2024-07-08 22:08:30,827] Trial 95 finished with value: 0.4484662576687117 and parameters: {'n_estimators': 104, 'learning_rate': 0.8125378817560464}. Best is trial 88 with value: 0.44969325153374234.\n",
      "[I 2024-07-08 22:08:35,287] Trial 96 finished with value: 0.447239263803681 and parameters: {'n_estimators': 208, 'learning_rate': 0.9243485014183738}. Best is trial 88 with value: 0.44969325153374234.\n",
      "[I 2024-07-08 22:08:38,910] Trial 97 finished with value: 0.0656441717791411 and parameters: {'n_estimators': 180, 'learning_rate': 0.010718198368693477}. Best is trial 88 with value: 0.44969325153374234.\n",
      "[I 2024-07-08 22:08:43,688] Trial 98 finished with value: 0.44907975460122695 and parameters: {'n_estimators': 225, 'learning_rate': 0.9932173350193514}. Best is trial 88 with value: 0.44969325153374234.\n",
      "[I 2024-07-08 22:08:48,551] Trial 99 finished with value: 0.447239263803681 and parameters: {'n_estimators': 235, 'learning_rate': 0.9884423190534172}. Best is trial 88 with value: 0.44969325153374234.\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d08f6ab5-62c1-435d-9f71-ab5c581e4dcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial: FrozenTrial(number=88, state=1, values=[0.44969325153374234], datetime_start=datetime.datetime(2024, 7, 8, 22, 8, 4, 674661), datetime_complete=datetime.datetime(2024, 7, 8, 22, 8, 7, 961835), params={'n_estimators': 159, 'learning_rate': 0.7814626294518465}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'n_estimators': IntDistribution(high=1000, log=False, low=50, step=1), 'learning_rate': FloatDistribution(high=1.0, log=False, low=0.001, step=None)}, trial_id=88, value=None)\n",
      "Best hyperparameters: {'n_estimators': 159, 'learning_rate': 0.7814626294518465}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best trial:\", study.best_trial)\n",
    "print(\"Best hyperparameters:\", study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2a2964-c64b-4398-ac8e-cc73abad0753",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
