{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8305d2b-05a2-4c03-96c1-41a8ed3e3f4e",
   "metadata": {},
   "source": [
    "## AdaBoost Hyperparameter Tuning (F1-Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1737f07b-25d7-4e9a-950e-c41ea036b4c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load Libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34b40b44-1c92-4b9d-ad57-3cddb44f6f0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load Data\n",
    "\n",
    "df = pd.read_csv('bank_4.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e25031a8-fef1-4150-86e7-8b7e22f0a9bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train / Test Split\n",
    "\n",
    "X = df.drop(columns=['churn', 'complain', 'umap_1', 'umap_2'])\n",
    "y = df['churn']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b530e97-2bc3-4b3d-b9f8-eb4ed610ff66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Hyperparameter tuning\n",
    "\n",
    "def objective(trial):\n",
    "\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 1000),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.001, 1.0)\n",
    "    }\n",
    "\n",
    "    model = AdaBoostClassifier(\n",
    "        **params,\n",
    "        random_state=42)\n",
    "    \n",
    "    threshold = 0.5\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n",
    "    scores = []\n",
    "    \n",
    "    for tr, te in skf.split(X_train, y_train):\n",
    "        \n",
    "        X_tr, X_te = X_train.iloc[tr], X_train.iloc[te]\n",
    "        y_tr, y_te = y_train.iloc[tr], y_train.iloc[te]\n",
    "        \n",
    "        model.fit(X_tr, y_tr)\n",
    "        prob = model.predict_proba(X_te)[:, 1]\n",
    "        y_pred = np.where(prob < threshold, 0, 1)\n",
    "        \n",
    "        scores.append(f1_score(y_te, y_pred))\n",
    "        \n",
    "    return np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb85a387-214c-480a-8a96-d69570dcbce9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-10 13:16:51,504] A new study created in memory with name: no-name-c1c1be00-8f6d-43ae-86de-38ec383b82cb\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a2355adfbc5408fa884b1cea1526331",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2024-07-10 13:17:11,997] Trial 0 finished with value: 0.5480569389626847 and parameters: {'n_estimators': 1000, 'learning_rate': 0.41275573238648755}. Best is trial 0 with value: 0.5480569389626847.\n",
      "[I 2024-07-10 13:17:15,207] Trial 1 finished with value: 0.541737835131191 and parameters: {'n_estimators': 139, 'learning_rate': 0.1977383117205113}. Best is trial 0 with value: 0.5480569389626847.\n",
      "[I 2024-07-10 13:17:21,025] Trial 2 finished with value: 0.5478098840093144 and parameters: {'n_estimators': 285, 'learning_rate': 0.472714180822971}. Best is trial 0 with value: 0.5480569389626847.\n",
      "[I 2024-07-10 13:17:41,440] Trial 3 finished with value: 0.5485441736464868 and parameters: {'n_estimators': 974, 'learning_rate': 0.23475213670350714}. Best is trial 3 with value: 0.5485441736464868.\n",
      "[I 2024-07-10 13:17:56,836] Trial 4 finished with value: 0.5483635958733972 and parameters: {'n_estimators': 755, 'learning_rate': 0.8851851871692377}. Best is trial 3 with value: 0.5485441736464868.\n",
      "[I 2024-07-10 13:18:12,113] Trial 5 finished with value: 0.5480569389626847 and parameters: {'n_estimators': 747, 'learning_rate': 0.5189458622010594}. Best is trial 3 with value: 0.5485441736464868.\n",
      "[I 2024-07-10 13:18:29,059] Trial 6 finished with value: 0.5479876553693487 and parameters: {'n_estimators': 838, 'learning_rate': 0.1254370562539692}. Best is trial 3 with value: 0.5485441736464868.\n",
      "[I 2024-07-10 13:18:33,701] Trial 7 finished with value: 0.5488354382763754 and parameters: {'n_estimators': 229, 'learning_rate': 0.6507070770234674}. Best is trial 7 with value: 0.5488354382763754.\n",
      "[I 2024-07-10 13:18:37,423] Trial 8 finished with value: 0.5495961039500312 and parameters: {'n_estimators': 175, 'learning_rate': 0.7295514052708609}. Best is trial 8 with value: 0.5495961039500312.\n",
      "[I 2024-07-10 13:18:51,847] Trial 9 finished with value: 0.5483635958733972 and parameters: {'n_estimators': 671, 'learning_rate': 0.952496688363382}. Best is trial 8 with value: 0.5495961039500312.\n",
      "[I 2024-07-10 13:19:01,406] Trial 10 finished with value: 0.5485613937239939 and parameters: {'n_estimators': 432, 'learning_rate': 0.7526705600818567}. Best is trial 8 with value: 0.5495961039500312.\n",
      "[I 2024-07-10 13:19:02,849] Trial 11 finished with value: 0.5483271263461319 and parameters: {'n_estimators': 62, 'learning_rate': 0.6687365220339118}. Best is trial 8 with value: 0.5495961039500312.\n",
      "[I 2024-07-10 13:19:09,063] Trial 12 finished with value: 0.5477038758110282 and parameters: {'n_estimators': 306, 'learning_rate': 0.6934179439081916}. Best is trial 8 with value: 0.5495961039500312.\n",
      "[I 2024-07-10 13:19:14,014] Trial 13 finished with value: 0.5479031966437462 and parameters: {'n_estimators': 232, 'learning_rate': 0.8008887515460108}. Best is trial 8 with value: 0.5495961039500312.\n",
      "[I 2024-07-10 13:19:23,214] Trial 14 finished with value: 0.5473451988677419 and parameters: {'n_estimators': 456, 'learning_rate': 0.5638116998046636}. Best is trial 8 with value: 0.5495961039500312.\n",
      "[I 2024-07-10 13:19:34,065] Trial 15 finished with value: 0.5477760569977652 and parameters: {'n_estimators': 543, 'learning_rate': 0.33949255929989386}. Best is trial 8 with value: 0.5495961039500312.\n",
      "[I 2024-07-10 13:19:37,494] Trial 16 finished with value: 0.5477366772700452 and parameters: {'n_estimators': 172, 'learning_rate': 0.6250945875475066}. Best is trial 8 with value: 0.5495961039500312.\n",
      "[I 2024-07-10 13:19:44,874] Trial 17 finished with value: 0.5485613937239939 and parameters: {'n_estimators': 363, 'learning_rate': 0.8431359187350322}. Best is trial 8 with value: 0.5495961039500312.\n",
      "[I 2024-07-10 13:19:46,786] Trial 18 finished with value: 0.5491957136063682 and parameters: {'n_estimators': 93, 'learning_rate': 0.9994395112630836}. Best is trial 8 with value: 0.5495961039500312.\n",
      "[I 2024-07-10 13:19:49,396] Trial 19 finished with value: 0.5477029271167281 and parameters: {'n_estimators': 129, 'learning_rate': 0.9776478473059553}. Best is trial 8 with value: 0.5495961039500312.\n",
      "[I 2024-07-10 13:19:50,457] Trial 20 finished with value: 0.5485654395411934 and parameters: {'n_estimators': 51, 'learning_rate': 0.9039702644207176}. Best is trial 8 with value: 0.5495961039500312.\n",
      "[I 2024-07-10 13:19:54,924] Trial 21 finished with value: 0.1229174476914204 and parameters: {'n_estimators': 217, 'learning_rate': 0.01212214483178553}. Best is trial 8 with value: 0.5495961039500312.\n",
      "[I 2024-07-10 13:20:01,651] Trial 22 finished with value: 0.5484679378019626 and parameters: {'n_estimators': 336, 'learning_rate': 0.7491049803391843}. Best is trial 8 with value: 0.5495961039500312.\n",
      "[I 2024-07-10 13:20:06,167] Trial 23 finished with value: 0.5488420863764508 and parameters: {'n_estimators': 227, 'learning_rate': 0.5904740441083689}. Best is trial 8 with value: 0.5495961039500312.\n",
      "[I 2024-07-10 13:20:08,638] Trial 24 finished with value: 0.540532477812041 and parameters: {'n_estimators': 120, 'learning_rate': 0.34518961176209884}. Best is trial 8 with value: 0.5495961039500312.\n",
      "[I 2024-07-10 13:20:20,132] Trial 25 finished with value: 0.5484645227296797 and parameters: {'n_estimators': 573, 'learning_rate': 0.564200969865931}. Best is trial 8 with value: 0.5495961039500312.\n",
      "[I 2024-07-10 13:20:28,961] Trial 26 finished with value: 0.5483635958733972 and parameters: {'n_estimators': 434, 'learning_rate': 0.9941731468969226}. Best is trial 8 with value: 0.5495961039500312.\n",
      "[I 2024-07-10 13:20:32,959] Trial 27 finished with value: 0.5477046451492784 and parameters: {'n_estimators': 199, 'learning_rate': 0.8332921944306398}. Best is trial 8 with value: 0.5495961039500312.\n",
      "[I 2024-07-10 13:20:34,892] Trial 28 finished with value: 0.5483473643816014 and parameters: {'n_estimators': 94, 'learning_rate': 0.7520979863529033}. Best is trial 8 with value: 0.5495961039500312.\n",
      "[I 2024-07-10 13:20:40,432] Trial 29 finished with value: 0.5470875084460673 and parameters: {'n_estimators': 276, 'learning_rate': 0.42992929456280865}. Best is trial 8 with value: 0.5495961039500312.\n",
      "[I 2024-07-10 13:20:48,548] Trial 30 finished with value: 0.5477038758110282 and parameters: {'n_estimators': 391, 'learning_rate': 0.5768916289512631}. Best is trial 8 with value: 0.5495961039500312.\n",
      "[I 2024-07-10 13:20:53,458] Trial 31 finished with value: 0.5493936677658372 and parameters: {'n_estimators': 244, 'learning_rate': 0.6358693091743826}. Best is trial 8 with value: 0.5495961039500312.\n",
      "[I 2024-07-10 13:20:56,737] Trial 32 finished with value: 0.5487615191817354 and parameters: {'n_estimators': 160, 'learning_rate': 0.7090309338105308}. Best is trial 8 with value: 0.5495961039500312.\n",
      "[I 2024-07-10 13:21:02,387] Trial 33 finished with value: 0.5479398024493823 and parameters: {'n_estimators': 282, 'learning_rate': 0.4975273819783198}. Best is trial 8 with value: 0.5495961039500312.\n",
      "[I 2024-07-10 13:21:04,726] Trial 34 finished with value: 0.5479285860191518 and parameters: {'n_estimators': 113, 'learning_rate': 0.6104077721441545}. Best is trial 8 with value: 0.5495961039500312.\n",
      "[I 2024-07-10 13:21:08,191] Trial 35 finished with value: 0.5466694639073033 and parameters: {'n_estimators': 173, 'learning_rate': 0.3898050228733533}. Best is trial 8 with value: 0.5495961039500312.\n",
      "[I 2024-07-10 13:21:13,352] Trial 36 finished with value: 0.5487725659387025 and parameters: {'n_estimators': 256, 'learning_rate': 0.9185322380228467}. Best is trial 8 with value: 0.5495961039500312.\n",
      "[I 2024-07-10 13:21:19,857] Trial 37 finished with value: 0.5479702186413409 and parameters: {'n_estimators': 320, 'learning_rate': 0.45314903392116657}. Best is trial 8 with value: 0.5495961039500312.\n",
      "[I 2024-07-10 13:21:39,232] Trial 38 finished with value: 0.5483635958733972 and parameters: {'n_estimators': 952, 'learning_rate': 0.5186886734348441}. Best is trial 8 with value: 0.5495961039500312.\n",
      "[I 2024-07-10 13:21:49,869] Trial 39 finished with value: 0.5483635958733972 and parameters: {'n_estimators': 483, 'learning_rate': 0.8039125592602133}. Best is trial 8 with value: 0.5495961039500312.\n",
      "[I 2024-07-10 13:21:57,645] Trial 40 finished with value: 0.5491264998551934 and parameters: {'n_estimators': 381, 'learning_rate': 0.24320808699236923}. Best is trial 8 with value: 0.5495961039500312.\n",
      "[I 2024-07-10 13:22:05,415] Trial 41 finished with value: 0.548209563595287 and parameters: {'n_estimators': 362, 'learning_rate': 0.2622820015888307}. Best is trial 8 with value: 0.5495961039500312.\n",
      "[I 2024-07-10 13:22:09,587] Trial 42 finished with value: 0.5393711660889198 and parameters: {'n_estimators': 199, 'learning_rate': 0.11618216043340251}. Best is trial 8 with value: 0.5495961039500312.\n",
      "[I 2024-07-10 13:22:14,614] Trial 43 finished with value: 0.5481553432803868 and parameters: {'n_estimators': 251, 'learning_rate': 0.26183844909834386}. Best is trial 8 with value: 0.5495961039500312.\n",
      "[I 2024-07-10 13:22:22,554] Trial 44 finished with value: 0.5479027572873119 and parameters: {'n_estimators': 381, 'learning_rate': 0.6510825455178437}. Best is trial 8 with value: 0.5495961039500312.\n",
      "[I 2024-07-10 13:22:24,540] Trial 45 finished with value: 0.5332428386885628 and parameters: {'n_estimators': 98, 'learning_rate': 0.15714273337596896}. Best is trial 8 with value: 0.5495961039500312.\n",
      "[I 2024-07-10 13:22:30,663] Trial 46 finished with value: 0.5482716021845656 and parameters: {'n_estimators': 305, 'learning_rate': 0.6913934902274604}. Best is trial 8 with value: 0.5495961039500312.\n",
      "[I 2024-07-10 13:22:33,734] Trial 47 finished with value: 0.5477789009355132 and parameters: {'n_estimators': 154, 'learning_rate': 0.5987197776740396}. Best is trial 8 with value: 0.5495961039500312.\n",
      "[I 2024-07-10 13:22:35,251] Trial 48 finished with value: 0.542601321802425 and parameters: {'n_estimators': 73, 'learning_rate': 0.3931013130166854}. Best is trial 8 with value: 0.5495961039500312.\n",
      "[I 2024-07-10 13:22:47,849] Trial 49 finished with value: 0.5486239594677286 and parameters: {'n_estimators': 608, 'learning_rate': 0.537041571398559}. Best is trial 8 with value: 0.5495961039500312.\n",
      "[I 2024-07-10 13:22:52,618] Trial 50 finished with value: 0.14514392404693832 and parameters: {'n_estimators': 218, 'learning_rate': 0.013579913406826405}. Best is trial 8 with value: 0.5495961039500312.\n",
      "[I 2024-07-10 13:22:56,448] Trial 51 finished with value: 0.5488354382763754 and parameters: {'n_estimators': 186, 'learning_rate': 0.6284987413120166}. Best is trial 8 with value: 0.5495961039500312.\n",
      "[I 2024-07-10 13:23:01,274] Trial 52 finished with value: 0.548636175256515 and parameters: {'n_estimators': 238, 'learning_rate': 0.6656754184486102}. Best is trial 8 with value: 0.5495961039500312.\n",
      "[I 2024-07-10 13:23:04,077] Trial 53 finished with value: 0.5474908615158615 and parameters: {'n_estimators': 139, 'learning_rate': 0.4782515698318384}. Best is trial 8 with value: 0.5495961039500312.\n",
      "[I 2024-07-10 13:23:09,663] Trial 54 finished with value: 0.5490364149157559 and parameters: {'n_estimators': 275, 'learning_rate': 0.7390311945913972}. Best is trial 8 with value: 0.5495961039500312.\n",
      "[I 2024-07-10 13:23:17,947] Trial 55 finished with value: 0.548265965578313 and parameters: {'n_estimators': 405, 'learning_rate': 0.7261202443444666}. Best is trial 8 with value: 0.5495961039500312.\n",
      "[I 2024-07-10 13:23:28,181] Trial 56 finished with value: 0.5483635958733972 and parameters: {'n_estimators': 507, 'learning_rate': 0.8483209791404116}. Best is trial 8 with value: 0.5495961039500312.\n",
      "[I 2024-07-10 13:23:33,842] Trial 57 finished with value: 0.5486889088921949 and parameters: {'n_estimators': 282, 'learning_rate': 0.7829534835348921}. Best is trial 8 with value: 0.5495961039500312.\n",
      "[I 2024-07-10 13:23:40,520] Trial 58 finished with value: 0.5479937474177181 and parameters: {'n_estimators': 327, 'learning_rate': 0.8952544567611862}. Best is trial 8 with value: 0.5495961039500312.\n",
      "[I 2024-07-10 13:23:47,698] Trial 59 finished with value: 0.5481563359373267 and parameters: {'n_estimators': 357, 'learning_rate': 0.9354224168184182}. Best is trial 8 with value: 0.5495961039500312.\n",
      "[I 2024-07-10 13:23:49,294] Trial 60 finished with value: 0.5426912489293731 and parameters: {'n_estimators': 79, 'learning_rate': 0.5451071864556689}. Best is trial 8 with value: 0.5495961039500312.\n",
      "[I 2024-07-10 13:23:53,985] Trial 61 finished with value: 0.5493936677658372 and parameters: {'n_estimators': 223, 'learning_rate': 0.6495436977802648}. Best is trial 8 with value: 0.5495961039500312.\n",
      "[I 2024-07-10 13:23:59,351] Trial 62 finished with value: 0.5486540430484487 and parameters: {'n_estimators': 265, 'learning_rate': 0.6853311683779872}. Best is trial 8 with value: 0.5495961039500312.\n",
      "[I 2024-07-10 13:24:03,461] Trial 63 finished with value: 0.5488316088162357 and parameters: {'n_estimators': 203, 'learning_rate': 0.5855104794880391}. Best is trial 8 with value: 0.5495961039500312.\n",
      "[I 2024-07-10 13:24:06,412] Trial 64 finished with value: 0.5495466076203517 and parameters: {'n_estimators': 140, 'learning_rate': 0.7303730503478332}. Best is trial 8 with value: 0.5495961039500312.\n",
      "[I 2024-07-10 13:24:09,622] Trial 65 finished with value: 0.5492914846303959 and parameters: {'n_estimators': 139, 'learning_rate': 0.7833019626733303}. Best is trial 8 with value: 0.5495961039500312.\n",
      "[I 2024-07-10 13:24:12,557] Trial 66 finished with value: 0.5489847644216694 and parameters: {'n_estimators': 134, 'learning_rate': 0.7807429178014491}. Best is trial 8 with value: 0.5495961039500312.\n",
      "[I 2024-07-10 13:24:13,598] Trial 67 finished with value: 0.5448256311270965 and parameters: {'n_estimators': 50, 'learning_rate': 0.9605908416171633}. Best is trial 8 with value: 0.5495961039500312.\n",
      "[I 2024-07-10 13:24:15,953] Trial 68 finished with value: 0.5518392752384444 and parameters: {'n_estimators': 109, 'learning_rate': 0.846886313092084}. Best is trial 68 with value: 0.5518392752384444.\n",
      "[I 2024-07-10 13:24:18,192] Trial 69 finished with value: 0.5485149519983394 and parameters: {'n_estimators': 110, 'learning_rate': 0.8628648285873641}. Best is trial 68 with value: 0.5518392752384444.\n",
      "[I 2024-07-10 13:24:21,384] Trial 70 finished with value: 0.5507293856593489 and parameters: {'n_estimators': 158, 'learning_rate': 0.8186210652829152}. Best is trial 68 with value: 0.5518392752384444.\n",
      "[I 2024-07-10 13:24:24,642] Trial 71 finished with value: 0.5499637237780393 and parameters: {'n_estimators': 158, 'learning_rate': 0.8258503654589215}. Best is trial 68 with value: 0.5518392752384444.\n",
      "[I 2024-07-10 13:24:27,870] Trial 72 finished with value: 0.5509175955651007 and parameters: {'n_estimators': 155, 'learning_rate': 0.8243666797853824}. Best is trial 68 with value: 0.5518392752384444.\n",
      "[I 2024-07-10 13:24:31,081] Trial 73 finished with value: 0.5501077891701518 and parameters: {'n_estimators': 156, 'learning_rate': 0.816849534916886}. Best is trial 68 with value: 0.5518392752384444.\n",
      "[I 2024-07-10 13:24:34,525] Trial 74 finished with value: 0.5492437386579779 and parameters: {'n_estimators': 169, 'learning_rate': 0.8169020290340259}. Best is trial 68 with value: 0.5518392752384444.\n",
      "[I 2024-07-10 13:24:38,203] Trial 75 finished with value: 0.5485596107879638 and parameters: {'n_estimators': 178, 'learning_rate': 0.8723552701885781}. Best is trial 68 with value: 0.5518392752384444.\n",
      "[I 2024-07-10 13:24:39,884] Trial 76 finished with value: 0.5485514684754162 and parameters: {'n_estimators': 82, 'learning_rate': 0.8212888228685188}. Best is trial 68 with value: 0.5518392752384444.\n",
      "[I 2024-07-10 13:24:42,955] Trial 77 finished with value: 0.5487302168064435 and parameters: {'n_estimators': 150, 'learning_rate': 0.7652102464200479}. Best is trial 68 with value: 0.5518392752384444.\n",
      "[I 2024-07-10 13:24:45,311] Trial 78 finished with value: 0.5483708940786981 and parameters: {'n_estimators': 114, 'learning_rate': 0.8889402148362601}. Best is trial 68 with value: 0.5518392752384444.\n",
      "[I 2024-07-10 13:24:49,226] Trial 79 finished with value: 0.5477135987516624 and parameters: {'n_estimators': 191, 'learning_rate': 0.8448845639732995}. Best is trial 68 with value: 0.5518392752384444.\n",
      "[I 2024-07-10 13:24:51,714] Trial 80 finished with value: 0.5485286686985138 and parameters: {'n_estimators': 120, 'learning_rate': 0.7955110826227632}. Best is trial 68 with value: 0.5518392752384444.\n",
      "[I 2024-07-10 13:24:55,120] Trial 81 finished with value: 0.5496327788174256 and parameters: {'n_estimators': 169, 'learning_rate': 0.7172732576991537}. Best is trial 68 with value: 0.5518392752384444.\n",
      "[I 2024-07-10 13:25:09,923] Trial 82 finished with value: 0.5483635958733972 and parameters: {'n_estimators': 715, 'learning_rate': 0.7201036585198768}. Best is trial 68 with value: 0.5518392752384444.\n",
      "[I 2024-07-10 13:25:13,407] Trial 83 finished with value: 0.5494595151968382 and parameters: {'n_estimators': 160, 'learning_rate': 0.7467752547761001}. Best is trial 68 with value: 0.5518392752384444.\n",
      "[I 2024-07-10 13:25:16,895] Trial 84 finished with value: 0.5488664952925213 and parameters: {'n_estimators': 155, 'learning_rate': 0.7521195334621738}. Best is trial 68 with value: 0.5518392752384444.\n",
      "[I 2024-07-10 13:25:21,198] Trial 85 finished with value: 0.5479121559030291 and parameters: {'n_estimators': 210, 'learning_rate': 0.8228293794726353}. Best is trial 68 with value: 0.5518392752384444.\n",
      "[I 2024-07-10 13:25:23,017] Trial 86 finished with value: 0.5471046221871808 and parameters: {'n_estimators': 89, 'learning_rate': 0.920370874932185}. Best is trial 68 with value: 0.5518392752384444.\n",
      "[I 2024-07-10 13:25:24,261] Trial 87 finished with value: 0.5452112646093229 and parameters: {'n_estimators': 60, 'learning_rate': 0.7048409593397311}. Best is trial 68 with value: 0.5518392752384444.\n",
      "[I 2024-07-10 13:25:27,924] Trial 88 finished with value: 0.5482716021845656 and parameters: {'n_estimators': 178, 'learning_rate': 0.8618916854362959}. Best is trial 68 with value: 0.5518392752384444.\n",
      "[I 2024-07-10 13:25:44,444] Trial 89 finished with value: 0.5483635958733972 and parameters: {'n_estimators': 817, 'learning_rate': 0.7369787787791736}. Best is trial 68 with value: 0.5518392752384444.\n",
      "[I 2024-07-10 13:25:47,242] Trial 90 finished with value: 0.547367217546571 and parameters: {'n_estimators': 132, 'learning_rate': 0.7601574125105303}. Best is trial 68 with value: 0.5518392752384444.\n",
      "[I 2024-07-10 13:25:51,864] Trial 91 finished with value: 0.5479125548192407 and parameters: {'n_estimators': 231, 'learning_rate': 0.6729898051657692}. Best is trial 68 with value: 0.5518392752384444.\n",
      "[I 2024-07-10 13:25:53,888] Trial 92 finished with value: 0.5489469031535421 and parameters: {'n_estimators': 97, 'learning_rate': 0.8043372399595001}. Best is trial 68 with value: 0.5518392752384444.\n",
      "[I 2024-07-10 13:25:57,110] Trial 93 finished with value: 0.5495966372983454 and parameters: {'n_estimators': 158, 'learning_rate': 0.7186753717990246}. Best is trial 68 with value: 0.5518392752384444.\n",
      "[I 2024-07-10 13:26:00,263] Trial 94 finished with value: 0.5490539582934212 and parameters: {'n_estimators': 155, 'learning_rate': 0.7031988980028193}. Best is trial 68 with value: 0.5518392752384444.\n",
      "[I 2024-07-10 13:26:04,024] Trial 95 finished with value: 0.5472977810991826 and parameters: {'n_estimators': 185, 'learning_rate': 0.8368332388755136}. Best is trial 68 with value: 0.5518392752384444.\n",
      "[I 2024-07-10 13:26:06,249] Trial 96 finished with value: 0.5461422866918026 and parameters: {'n_estimators': 105, 'learning_rate': 0.7662269559244025}. Best is trial 68 with value: 0.5518392752384444.\n",
      "[I 2024-07-10 13:26:10,383] Trial 97 finished with value: 0.5489858878988513 and parameters: {'n_estimators': 205, 'learning_rate': 0.8764441915970682}. Best is trial 68 with value: 0.5518392752384444.\n",
      "[I 2024-07-10 13:26:13,713] Trial 98 finished with value: 0.5491944047459769 and parameters: {'n_estimators': 166, 'learning_rate': 0.911521613928996}. Best is trial 68 with value: 0.5518392752384444.\n",
      "[I 2024-07-10 13:26:19,978] Trial 99 finished with value: 0.5473362396084591 and parameters: {'n_estimators': 305, 'learning_rate': 0.7223456378943317}. Best is trial 68 with value: 0.5518392752384444.\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d08f6ab5-62c1-435d-9f71-ab5c581e4dcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial: FrozenTrial(number=68, state=1, values=[0.5518392752384444], datetime_start=datetime.datetime(2024, 7, 10, 13, 24, 13, 600598), datetime_complete=datetime.datetime(2024, 7, 10, 13, 24, 15, 953288), params={'n_estimators': 109, 'learning_rate': 0.846886313092084}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'n_estimators': IntDistribution(high=1000, log=False, low=50, step=1), 'learning_rate': FloatDistribution(high=1.0, log=False, low=0.001, step=None)}, trial_id=68, value=None)\n",
      "Best hyperparameters: {'n_estimators': 109, 'learning_rate': 0.846886313092084}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best trial:\", study.best_trial)\n",
    "print(\"Best hyperparameters:\", study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2a2964-c64b-4398-ac8e-cc73abad0753",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
